<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title></title>
  <meta name="description" content="">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="" />
  
  
  




  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  


<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="https://cdn.datacamp.com/datacamp-light-latest.min.js"></script>



<link rel="stylesheet" href="css\style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./"><img src="images/logovision-black.png" width="160"></img></a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path=""><a href="#espacios-vectoriales"><i class="fa fa-check"></i><b>1</b> Espacios vectoriales</a><ul>
<li class="chapter" data-level="1.1" data-path=""><a href="#ecuaciones-lineales"><i class="fa fa-check"></i><b>1.1</b> Ecuaciones lineales</a></li>
<li class="chapter" data-level="1.2" data-path=""><a href="#matrices"><i class="fa fa-check"></i><b>1.2</b> Matrices</a></li>
<li class="chapter" data-level="1.3" data-path=""><a href="#ecuaciones-lineales-y-matrices"><i class="fa fa-check"></i><b>1.3</b> Ecuaciones lineales y matrices</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="blank">Publicado con bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"></a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<!--bookdown:title:end-->
<!--bookdown:title:start-->
<div id="espacios-vectoriales" class="section level1">
<h1><span class="header-section-number">Capítulo 1</span> Espacios vectoriales</h1>
<p>En este capítulo estudiaremos los espacios vectoriales, un concepto abstrato de una estructura cerrada bajo combinaciones lineales. Veremos que las matrices son objetos muy útiles para trabajar en espacios vectoriales. Por esta razón estudiaremos algunos aspectos básicos de estos objetos. Como motivación para el estudio de las matrices iniciaremos el capítulo estudiando las ecuaciones lineales y poco a poco iremos acercándonos al estudio de los espacios vectoriales.</p>
<div id="ecuaciones-lineales" class="section level2">
<h2><span class="header-section-number">1.1</span> Ecuaciones lineales</h2>
<p>En este sección estudiaremos las ecuaciones lineales como motivación para el estudio de los conceptos iniciales de matrices. Además estudiaremos las operaciones básicas de suma y producto por un escalar así como el producto de matrices. Luego estudiaremos el concepto de invertibilidad de matrices, para ello definiremos las operaciones elementales por filas.</p>
Sea <span class="math inline">\(\mathbb{F}\)</span> un cuerpo. Supongamos que queremos hallar <span class="math inline">\(n\)</span> escalares (elementos del cuerpo <span class="math inline">\(\mathbb{F}\)</span>) <span class="math inline">\(x_{1},x_{2}, \cdots, x_{n}\)</span> que satisfagan las condiciones:
<span class="math display" id="eq:sistemalineal">\[\begin{equation}
    \begin{array}{ccccc}
        A_{11}x_{1}+&amp;A_{12}x_{2}+&amp;\cdots +&amp;A_{1n}x_{n}=&amp;b_{1}\\
        A_{21}x_{1}+&amp;A_{22}x_{2}+&amp;\cdots +&amp;A_{2n}x_{n}=&amp;b_{2}\\
        \vdots&amp; &amp;\ddots&amp; \vdots&amp; \vdots \\
        A_{m1}x_{1}+&amp;A_{m2}x_{2}+&amp;\cdots +&amp;A_{mn}x_{n}=&amp;b_{m}
    \end{array}
    \tag{1.1}
\end{equation}\]</span>
<p>donde <span class="math inline">\(b_{i}\in\mathbb{F}\)</span> así como <span class="math inline">\(A_{ij}\in \mathbb{F}\)</span> para todo <span class="math inline">\(1\leq i\leq m\)</span> y <span class="math inline">\(1\leq j\leq n\)</span>. Al conjunto de ecuaciones expresadas en <a href="#eq:sistemalineal">(1.1)</a> se le llama <em>sistema de <span class="math inline">\(m\)</span> ecuaciones lineales con <span class="math inline">\(n\)</span> incognitas</em>. A los elementos <span class="math inline">\(A_{ij}\)</span> se les conoce como <em>coeficientes</em> del sistema de ecuaciones, siendo específicamente el coeficiente de la <span class="math inline">\(i\)</span>-ésima fila y la <span class="math inline">\(j\)</span>-ésima columna. Una <em>solución</em> del sistema es una <span class="math inline">\(n\)</span>-tupla <span class="math inline">\((x_{1},x_{2},\cdots,x_{n})\)</span> (un vector del espacio <span class="math inline">\(\mathbb{R}^{n}\)</span>) que satisfaga las ecuaciones <a href="#eq:sistemalineal">(1.1)</a>. Cuando <span class="math inline">\(b_{1}=b_{2}=\cdots b_{m}=0\)</span> se dice que el <em>sistema de ecuaciones es homogéneo</em> (cada ecuación es homogénea).</p>
<p>Una forma de resolver un sistema de ecuaciones es con la técnica de eliminación de incógnitas, el cual consiste en multiplicar algunas de las ecuaciones por un escalar de forma que al sumar las ecuaciones se elimine algunas de las incógnitas. Veamos esto con un ejemplo.</p>

<div class="example">
<span id="exm:unnamed-chunk-1" class="example"><strong>Ejemplo 1.1  </strong></span> Dado el siguiente sistema homogéneo, sobre el cuerpo de los números reales <span class="math inline">\(\mathbb{R}\)</span>
<span class="math display">\[\begin{eqnarray*}
    \begin{array}{cc}
        x_{1}-4x_{2}+x_{3}&amp;=0\\
        3x_{1}-11x_{2}+2x_{3}&amp;=0
    \end{array}
    \end{eqnarray*}\]</span>
<p>Multiplicamos la primera ecuación por el escalar <span class="math inline">\(-3\)</span> y la sumamos a la segunda ecuación, para obtener <span class="math inline">\(-3(x_{1}-4x_{2}+x_{3})+(3x_{1}-11x_{2}+2x_{3})=0\)</span>, lo que queda como la siguiente <span class="math inline">\(-3x_{1}+12x_{2}-3x_{3}+3x_{1}-11x_{2}+2x_{3}=0\)</span>, sumando términos independientes, obtenemos <span class="math inline">\(x_{2}-x_{3}=0\)</span> por lo tanto <span class="math inline">\(x_{2}=x_{3}\)</span>. Ahora, multiplicando por <span class="math inline">\(-2\)</span> la primera ecuación y sumándola a la segunda, se obtiene <span class="math inline">\(-2(x_{1}-4x_{2}+x_{3})+(3x_{1}-11x_{2}+2x_{3})=0\)</span> lo que equivale a <span class="math inline">\(-2x_{1}+8x_{2}-2x_{3}+3x_{1}-11x_{2}+2x_{3}=0\)</span> al sumar los términos semejantes se obtiene que <span class="math inline">\(x_{1}-3x_{2}=0\)</span> por lo que <span class="math inline">\(x_{1}=3x_{2}\)</span>. Luego cualquier vector de la forma <span class="math inline">\((3\lambda,\lambda,\lambda)\)</span> con <span class="math inline">\(\lambda\in\mathbb{R}\)</span> es una solución del sistema homogéneo.</p>
</div>

En general, este método para resolver un sistema de ecuaciones como <a href="#eq:sistemalineal">(1.1)</a> consiste en multiplicar por <span class="math inline">\(m\)</span> escalares <span class="math inline">\(c_{1}, c_{2},\cdots ,c_{m}\)</span> cada ecuación del sistema y sumarlas entre si para obtener una <em>combinación lineal</em> de las ecuaciones:
<span class="math display">\[\begin{equation}
\begin{array}{ccccccc}
&amp;c_{1}(A_{11}x_{1}&amp;+&amp;\cdots &amp;+&amp;A_{1n}x_{n})=&amp;c_{1}b_{1}\\
&amp;c_{2}(A_{21}x_{1}&amp;+&amp;\cdots &amp;+&amp;A_{2n}x_{n})=&amp;c_{2}b_{2}\\
+&amp;\vdots&amp; &amp;\ddots&amp; &amp;\vdots&amp; \vdots  \\
&amp;c_{m}(A_{m1}x_{1}&amp;+&amp;\cdots &amp;+&amp;A_{mn}x_{n})=&amp;c_{m}b_{m}\\
\cline{2-7}
&amp;(c_{1}A_{11}+\cdots+c_{m}A_{m1})x_{1}&amp;+&amp;\cdots&amp;+&amp;(c_{1}A_{1n}+\cdots +c_{m}A_{mn})x_{n}&amp;=c_{1}b_{1}+\cdots+c_{m}b_{m}
\end{array}
\end{equation}\]</span>
Es claro que cualquier solución del sistema <a href="#eq:sistemalineal">(1.1)</a> es solución de la combinación lineal antes descrita. Ahora bien, si formamos un sistema de <span class="math inline">\(k\)</span> ecuaciones lineales en las que cada una de ellas es una combinación lineal de las <span class="math inline">\(m\)</span> ecuaciones del sistema original, como sigue:
<span class="math display" id="eq:sistema2">\[\begin{equation}
\begin{array}{ccccc}
B_{11}x_{1}+&amp;B_{12}x_{2}+&amp;\cdots +&amp;B_{1n}x_{n}=&amp;d_{1}\\
B_{21}x_{1}+&amp;B_{22}x_{2}+&amp;\cdots +&amp;B_{2n}x_{n}=&amp;d_{2}\\
\vdots&amp; &amp;\ddots&amp; \vdots&amp; \vdots \\
B_{k1}x_{1}+&amp;B_{k2}x_{2}+&amp;\cdots +&amp;B_{kn}x_{n}=&amp;d_{k}
\end{array}
\end{equation}\]</span>
<p>\tag{1.2}</p>
<p>se tiene que <span class="math inline">\((x_{1},x_{2},\cdots, x_{n})\)</span> es solución de <a href="#eq:sistema2">(1.2)</a> si lo es del sistema <a href="#eq:sistemalineal">(1.1)</a>. Lo contrario no es necesariamente cierto, sin embargo si las ecuaciones de <a href="#eq:sistemalineal">(1.1)</a> son combinación lineal de las ecuaciones <a href="#eq:sistema2">(1.2)</a> entonces podemos estar seguros que toda solución del sistema <a href="#eq:sistema2">(1.2)</a> es también solución de <a href="#eq:sistemalineal">(1.1)</a>. En este caso diremos que <em>son sistemas de ecuaciones equivalentes</em>. Y la observación podemos señalarla así:</p>

<div class="theorem">
<span id="thm:unnamed-chunk-2" class="theorem"><strong>Teorema 1.1  </strong></span> Sistemas de ecuaciones lineales equivalentes tienen exactamente las mismas soluciones.
</div>

<p>Lo anterior nos permite buscar las soluciones de cualquier sistema de ecuaciones lineales, buscando un sistema equivalente que sea mas fácil de resolver (por excelencia, trivial). Este método lo explicaremos en la siguiente sección.</p>
</div>
<div id="matrices" class="section level2">
<h2><span class="header-section-number">1.2</span> Matrices</h2>
<p>En la sección anterior vimos que cuando realizamos combinaciones lineales de ecuaciones lineales, lo que importa son los coeficientes de las ecuaciones originales, siendo las incógnitas prescindibles. Esto nos permite trabajar directamente con los coeficientes para hallar un nuevo sistema lineal equivalente mas sencillo. Por esta razón arreglaremos tales coeficientes en forma rectángular para trabajar con ellos de forma directa. Estos objetos se llaman <em>matrices</em>. En la primera parte de esta sección se dará una definición formal y mas general de estos objetos, se definiran algunas operaciones con estos objetos. Para luego volver al problema original, la resolución de sistemas de ecuaciones lineales.</p>

<div class="definition">
<span id="def:unnamed-chunk-3" class="definition"><strong>Definición 1.1  </strong></span> Para enteros positivos <span class="math inline">\(m\)</span> y <span class="math inline">\(n\)</span>, <em>una matriz <span class="math inline">\(m\times n\)</span> sobre el cuerpo <span class="math inline">\(\mathbb{F}\)</span></em> es una función <span class="math inline">\(A\)</span> del conjunto de los pares <span class="math inline">\((i,j)\in\{1,2,\cdots m\}\times\{1,2,\cdots n\}\)</span> en el cuerpo <span class="math inline">\(\mathbb{F}\)</span>. El <em>orden de la matriz <span class="math inline">\(A\)</span></em> es <span class="math inline">\(m\times n\)</span>. Los <em>elementos de la matriz <span class="math inline">\(A\)</span></em> son los escalares <span class="math inline">\(A(i,j)=a_{ij}\)</span>. Suele representarse como un arreglo rectángular de <span class="math inline">\(m\)</span> filas y <span class="math inline">\(n\)</span> columnas, donde el elemento <span class="math inline">\(a_{ij}\)</span> ocupa el puesto en la fila <span class="math inline">\(i\)</span> y la columna <span class="math inline">\(j\)</span> del arreglo, como sigue
<span class="math display">\[\begin{equation*}
        \left[ \begin{array}{cccc}
        a_{11}&amp;a_{12}&amp;\cdots &amp;a_{1n}\\
        a_{21}&amp;a_{22}&amp;\cdots &amp;a_{2n}\\
        \vdots&amp; \ddots&amp; \vdots&amp; \vdots\\
        a_{m1}&amp;a_{m2}&amp;\cdots &amp;a_{mn}
        \end{array}\right] 
    \end{equation*}\]</span>
<p>La <em><span class="math inline">\(i\)</span>-ésima fila de la matriz <span class="math inline">\(A\)</span></em> es el arreglo <span class="math inline">\(A_{i*}=[a_{i1}\; a_{i2}\;\cdots\; a_{in}]\)</span> (puede entenderse como un vector de <span class="math inline">\(\mathbb{R}^{n}\)</span>) y la  es el arreglo <span class="math inline">\(A_{*j}=\left[ \begin{array}{c}a_{1j}\\  a_{2j}\\  \vdots\\  a_{mj}  \end{array}\right]\)</span>.</p>
</div>


<div class="definition">
<span id="def:unnamed-chunk-4" class="definition"><strong>Definición 1.2  </strong></span> Dadas las matrices <span class="math inline">\(A\)</span> y <span class="math inline">\(B\)</span> de orden <span class="math inline">\(n\times m\)</span>, sobre el cuerpo <span class="math inline">\(\mathbb{F}\)</span>, <em>la suma de las matrices <span class="math inline">\(A\)</span> y <span class="math inline">\(B\)</span></em>, es la matriz <span class="math inline">\(A+B\)</span> formada por los elementos <span class="math inline">\((a+b)_{ij}=a_{ij}+b_{ij}\)</span> (la función suma <span class="math inline">\((A+B)(i,j)=A(i,j)+B(i,j)\)</span>). También se puede expresar como:
<span class="math display">\[\begin{equation*}
        \left[ \begin{array}{cccc}
            a_{11} &amp; a_{12} &amp; \cdots &amp; a_{1n}\\
            a_{21} &amp; a_{22} &amp; \cdots &amp; a_{2n}\\
            \vdots &amp; \vdots &amp; \ddots &amp; \vdots\\
            a_{m1} &amp; a_{m2} &amp; \cdots &amp; a_{mn}\\
        \end{array}\right]+
        \left[ \begin{array}{cccc}
        b_{11} &amp; b_{12} &amp; \cdots &amp; b_{1n}\\
        b_{21} &amp; b_{22} &amp; \cdots &amp; b_{2n}\\
        \vdots &amp; \vdots &amp; \ddots &amp; \vdots\\
        b_{m1} &amp; b_{m2} &amp; \cdots &amp; b_{mn}\\
        \end{array}\right]=
        \left[ \begin{array}{cccc}
        a_{11} + b_{11}&amp; a_{12} + b_{12}&amp; \cdots &amp; a_{1n}+ b_{1n}\\
        a_{21} + b_{21} &amp; a_{22} + b_{22} &amp; \cdots &amp; a_{2n} + b_{2n}\\
        \vdots &amp; \vdots &amp; \ddots &amp; \vdots\\
        a_{m1} + b_{m1} &amp; a_{m2} + b_{m2} &amp; \cdots &amp; a_{mn} + b_{mn}\\
        \end{array}\right]
    \end{equation*}\]</span>
</div>
 
<div class="definition">
<span id="def:unnamed-chunk-5" class="definition"><strong>Definición 1.3  </strong></span> Dada una matriz <span class="math inline">\(A\)</span> de orden <span class="math inline">\(m\times n\)</span> sobre el cuerpo <span class="math inline">\(\mathbb{F}\)</span> y un escalar <span class="math inline">\(\lambda\in\mathbb{F}\)</span>. El <em>producto de la matriz <span class="math inline">\(A\)</span> por el escalar <span class="math inline">\(\lambda\)</span></em> es la matriz <span class="math inline">\(\lambda A\)</span>, donde cada elemento <span class="math inline">\([\lambda A]_{ij}=\lambda a_{ij}\)</span>, es decir:
<span class="math display">\[\begin{equation*}
        \lambda A=
        \lambda \left[ \begin{array}{cccc}
            a_{11} &amp; a_{12} &amp; \cdots &amp; a_{1n}\\
            a_{21} &amp; a_{22} &amp; \cdots &amp; a_{2n}\\
            \vdots &amp; \vdots &amp; \ddots &amp; \vdots\\
            a_{m1} &amp; a_{m2} &amp; \cdots &amp; a_{mn}\\
        \end{array}\right]=
        \left[ \begin{array}{cccc}
            \lambda a_{11}&amp; \lambda a_{12}&amp; \cdots &amp; \lambda a_{1n}\\
            \lambda a_{21}&amp; \lambda a_{22}&amp; \cdots &amp; \lambda a_{2n}\\
            \vdots &amp; \vdots &amp; \ddots &amp; \vdots\\
            \lambda a_{m1}&amp; \lambda a_{m2}&amp; \cdots &amp; \lambda a_{mn}\\
        \end{array}\right]
    \end{equation*}\]</span>
</div>


<div class="definition">
<p><span id="def:unnamed-chunk-6" class="definition"><strong>Definición 1.4  </strong></span> Sean <span class="math inline">\(A\)</span> y <span class="math inline">\(B\)</span> matrices de orden <span class="math inline">\(m\times n\)</span> y <span class="math inline">\(n\times p\)</span> respectivamente, el <em>producto <span class="math inline">\(AB\)</span></em> es la matriz <span class="math inline">\(C\)</span> de orden <span class="math inline">\(m\times p\)</span> cuyos elementos <span class="math inline">\(ij\)</span> son <span class="math inline">\([C]_{ij}=\sum_{k=1}^{n} A_{ik}B_{kj}\)</span>.</p>
</div>


<div class="example">
<p><span id="exm:unnamed-chunk-7" class="example"><strong>Ejemplo 1.2  </strong></span> Dadas las matrices <span class="math inline">\(A=\left[ \begin{array}{cc}  1 &amp; 0 \\  -3 &amp; 1  \end{array}\right]\)</span>, <span class="math inline">\(B=\left[ \begin{array}{ccc}  5 &amp; -1 &amp; 2 \\  15 &amp; 4 &amp; 8  \end{array}\right]\)</span> y <span class="math inline">\(C=\left[ \begin{array}{ccc}  -2 &amp; 1 &amp; 5\\  -1 &amp; -5 &amp; 1  \end{array}\right]\)</span>, entonces el producto de la matriz <span class="math inline">\(C\)</span> por el escalar <span class="math inline">\(-2\)</span> es: <span class="math display">\[-2 C=\left[ \begin{array}{ccc}
    (-2)(-2) &amp; (-2)(1) &amp; (-2)(5)\\
    (-2)(-1) &amp; (-2)(-5) &amp; (-2)(1)
    \end{array}\right]=\left[ \begin{array}{ccc}
    4 &amp; -2 &amp; -10\\
    2 &amp; 10 &amp; -2
    \end{array}\right]\]</span>. El producto <span class="math inline">\(AB\)</span> es la matriz: <span class="math display">\[\left[ \begin{array}{cc}
    1 &amp; 0 \\
    -3 &amp; 1
    \end{array}\right]\left[ \begin{array}{ccc}
    5 &amp; -1 &amp; 2 \\
    15 &amp; 4 &amp; 8
    \end{array}\right]=\left[ \begin{array}{ccc}
        5 &amp; -1 &amp; 2\\
        0 &amp; 7 &amp; 2
    \end{array}\right]\]</span> Y la suma <span class="math display">\[AB+C=\left[ \begin{array}{ccc}
        3 &amp; 0 &amp; 7\\
        -1 &amp; 2 &amp; 3
    \end{array}\right]\]</span> Note que no podemos realizar el producto <span class="math inline">\(BA\)</span>, pues no está definido. Para realizar un producto de matrices, el número de columnas del primer factor debe ser igual al número de filas del segundo factor.</p>
</div>


<div class="example">
<p><span id="exm:unnamed-chunk-8" class="example"><strong>Ejemplo 1.3  </strong></span> Dadas las matrices <span class="math inline">\(A=\left[ \begin{array}{cc}  1 &amp; -2 \\  0 &amp; 1 \\  -2 &amp; 0  \end{array}\right]\)</span> y <span class="math inline">\(B=\left[ \begin{array}{ccc}  1 &amp; 0 &amp; 1 \\  0 &amp; 2 &amp; 1  \end{array}\right]\)</span>, entonces los productos: <span class="math inline">\(AB=\left[ \begin{array}{ccc}  1 &amp; -4 &amp; -1\\  0 &amp; 2 &amp; 1 \\  -2 &amp; 0 &amp; -2  \end{array}\right]\)</span> y <span class="math inline">\(BA=\left[ \begin{array}{cc}  -1 &amp; -2 \\  -2 &amp; 2  \end{array}\right]\)</span>.\ Por otro lado, si se tienen las matrices <span class="math inline">\(C=\left[ \begin{array}{cc}  1 &amp; -2 \\  3 &amp; -1 \\  \end{array}\right]\)</span> y <span class="math inline">\(D=\left[ \begin{array}{cc}  1 &amp; -2 \\  -1 &amp; 2  \end{array}\right]\)</span>, entonces los productos: <span class="math inline">\(CD=\left[ \begin{array}{cc}  3 &amp; -6 \\  4 &amp; -7  \end{array}\right]\)</span> y <span class="math inline">\(DC=\left[ \begin{array}{cc}  -5 &amp; 0 \\  5 &amp; 0  \end{array}\right]\)</span></p>
</div>


<div class="remark">
<p> <span class="remark"><em>Nota. </em></span>  En los casos en que expresemos el producto <span class="math inline">\(AB\)</span> sin detallar el orden de las matrices, supondremos que el producto está bien definido. De los ejemplos anteriores podemos ver que aunque los productos <span class="math inline">\(AB\)</span> y <span class="math inline">\(BA\)</span> esten bien definidos, no necesariamente se tiene que <span class="math inline">\(AB=BA\)</span>, esto es, el producto de matrices no es conmutativo.</p>
</div>

<p>Ahora estudiaremos las <em>operaciones elementales de filas</em> que pueden aplicarse a una matriz, el fin de aplicar estas operaciones es obtener una matriz equivalente a la original (para obtener sistemas de ecuaciones lineales equivalentes) que corresponda a los coeficientes de un sistema lineal sencillo de resolver.</p>

<div class="definition">
<p><span id="def:unnamed-chunk-10" class="definition"><strong>Definición 1.5  </strong></span> Una matriz <span class="math inline">\(R\)</span> de orden <span class="math inline">\(m\times n\)</span> se llama una <em>matriz escalón reducida por filas</em> si:</p>
<pre><code>    (1) El primer elemento no nulo de cada fila no nula es igual a $1$, al cual llamaremos *pivote*.

    (2) las columnas que contienen a un pivote (de cualquier fila), tienen el restos de sus elemento igual a cero.

    (3) toda fila nula de $R$, está debajo de las filas con elementos no nulos.

    (4) suponiendo que las filas no nulas de $R$ son las filas $1,2,\cdots, r$ y que el pivote de la fila $i\leq r$ está en la columna $k_{i}$, entonces $k_{1}&lt; k_{2}&lt; \cdots &lt; k_{r}$.</code></pre>
</div>


<div class="remark">
<p> <span class="remark"><em>Nota. </em></span>  Una matriz que cumpla las primeras dos condiciones se llama <em>matriz reducida por filas</em>.</p>
</div>


<div class="example">
<p><span id="exm:unnamed-chunk-12" class="example"><strong>Ejemplo 1.4  </strong></span> La <em>matriz identidad</em> <span class="math inline">\(n\times n\)</span> (cuadrada), definida por la función <span class="math display">\[[I]_{ij}=delta_{ij}=\left\{ \begin{array}{cc}
    1 &amp;\mbox{ si } i=j\\
    0 &amp;\mbox{ si } i\neq j
    \end{array}\right. \]</span> La función <span class="math inline">\(\delta_{ij}\)</span> es conocida como la <em>delta de Kronecker</em>. Es de hacer notar que la matriz identidad se define como una matriz de cualquier orden, mientras que sea cuadrada, es decir, el número de filas es igual al número de columnas.Por ejemplo la matriz identidad de orden <span class="math inline">\(4\times 4\)</span> luce así: <span class="math display">\[\left[\begin{array}{cccc}
    1 &amp; 0 &amp; 0 &amp; 0\\
    0 &amp; 1 &amp; 0 &amp; 0\\
    0 &amp; 0 &amp; 1 &amp; 0\\
    0 &amp; 0 &amp; 0 &amp; 1
    \end{array} \right]\]</span> Las matrices <span class="math display">\[\left[\begin{array}{cccc}
    0 &amp; 1 &amp; 0 &amp; 4\\
    0 &amp; 0 &amp; 1 &amp; 5\\
    0 &amp; 0 &amp; 0 &amp; 0
    \end{array} \right] \mbox{ y }
    \left[\begin{array}{ccccc}
    0 &amp; 1 &amp; -3 &amp; 0 &amp; \frac{1}{2}\\
    0 &amp; 0 &amp; 0 &amp; 1 &amp; 2\\
    0 &amp; 0 &amp; 0 &amp; 0 &amp; 0
    \end{array} \right] \]</span> son matrices escalonadas reducidas. Pero estas matrices<br />
<span class="math display">\[\left[\begin{array}{cccc}
    0 &amp; 1 &amp; 0 &amp; 4\\
    0 &amp; 0 &amp; 1 &amp; 5\\
    0 &amp; 0 &amp; 0 &amp; 2
    \end{array} \right] \mbox{ y }\left[\begin{array}{cccc}
    0 &amp; 1 &amp; 0 &amp; \frac{4}{3}\\
    0 &amp; 0 &amp; 1 &amp; 5\\
    1 &amp; 0 &amp; 0 &amp; -1
    \end{array} \right]\]</span> no lo son. La primera no lo es ya que el primer elemento no nulo de la última fila no es <span class="math inline">\(1\)</span>. La segunda matriz no cumple la definición, el pivote de la tercera fila está en la columna <span class="math inline">\(1\)</span>, mientras que el de la primera primera fila está en la columna <span class="math inline">\(2\)</span> (<span class="math inline">\(2\nless 1\)</span>).</p>
</div>

<p>Podremos ver mas adelante que los sistemas de ecuaciones asociadas a matrices escalonadas reducidas son mas fáciles de resolver. Entonces es conveniente hallar una matriz escalonada reducida que tenga un sistema de ecuaciones equivalente al original para así resolver el sistema fácilmente.</p>
</div>
<div id="ecuaciones-lineales-y-matrices" class="section level2">
<h2><span class="header-section-number">1.3</span> Ecuaciones lineales y matrices</h2>
Dado un sistema de ecuaciones lineales como <a href="#eq:sistemalineal">(1.1)</a>
<span class="math display">\[\begin{equation}
\begin{array}{ccccc}
A_{11}x_{1}+&amp;A_{12}x_{2}+&amp;\cdots +&amp;A_{1n}x_{n}=&amp;b_{1}\\
A_{21}x_{1}+&amp;A_{22}x_{2}+&amp;\cdots +&amp;A_{2n}x_{n}=&amp;b_{2}\\
\vdots&amp; &amp;\ddots&amp; \vdots&amp; \vdots \\
A_{m1}x_{1}+&amp;A_{m2}x_{2}+&amp;\cdots +&amp;A_{mn}x_{n}=&amp;b_{m}
\end{array}
\end{equation}\]</span>
Podemos representar este sistema de ecuaciones como un sistema matricial <span class="math inline">\(AX=B\)</span>, donde <span class="math inline">\(A\)</span> es la matriz de los coeficientes del sistema de ecuaciones, <span class="math inline">\(X\)</span> es una matriz de incógnitas y <span class="math inline">\(B\)</span> una matriz de términos independientes de la siguiente forma:
<span class="math display">\[\begin{equation}
    \left[ \begin{array}{cccc}
        A_{11}&amp;A_{12}&amp;\cdots &amp;A_{1n}\\
        A_{21}&amp;A_{22}&amp;\cdots &amp;A_{2n}\\
        \vdots&amp; \ddots&amp; \vdots&amp; \vdots\\
        A_{m1}&amp;A_{m2}&amp;\cdots &amp;A_{mn}
    \end{array}\right] 
    \cdot
    \left[ \begin{array}{c}
        x_{1}\\
        x_{2}\\
        \vdots\\
        x_{n}
    \end{array}\right] =
    \left[ \begin{array}{c}
        b_{1}\\
        b_{2}\\
        \vdots\\
        b_{n}
    \end{array}\right] 
\end{equation}\]</span>

<div class="theorem">
<p><span id="thm:unnamed-chunk-13" class="theorem"><strong>Teorema 1.2  </strong></span> Sean <span class="math inline">\(A\)</span>, <span class="math inline">\(B\)</span> y <span class="math inline">\(C\)</span> matrices sobre el cuerpo de escalares <span class="math inline">\(\mathbb{F}\)</span>. Supongamos que los productos <span class="math inline">\(BC\)</span> y <span class="math inline">\(A(BC)\)</span> están definidos. Entonces, <span class="math inline">\(AB\)</span> y <span class="math inline">\((AB)C\)</span> también están definidos y <span class="math inline">\(A(BC)=(AB)C\)</span>.</p>
</div>


<div class="proof">
<p> <span class="proof"><em>Demostración. </em></span>  Como <span class="math inline">\(BC\)</span> y <span class="math inline">\(A(BC)\)</span> están definidos, se tiene que el número de columnas de <span class="math inline">\(B\)</span> es igual al número de filas de <span class="math inline">\(C\)</span> y que el número de columnas de <span class="math inline">\(A\)</span> es igual al número de filas de <span class="math inline">\(BC\)</span> (y por lo tanto, igual al número de filas de <span class="math inline">\(B\)</span>). Supongamos que <span class="math inline">\(B\)</span> es de orden <span class="math inline">\(n\times p\)</span>, <span class="math inline">\(C\)</span> es de orden <span class="math inline">\(p\times q\)</span> y <span class="math inline">\(A\)</span> de orden <span class="math inline">\(m\times n\)</span>, así <span class="math inline">\(A(BC)\)</span> es de orden <span class="math inline">\(m\times q\)</span>. Claramente, <span class="math inline">\(AB\)</span> está definida y será de orden <span class="math inline">\(m\times p\)</span>, como <span class="math inline">\(C\)</span> es de orden <span class="math inline">\(p\times q\)</span>, <span class="math inline">\((AB)C\)</span> está bien definido y será de orden <span class="math inline">\(m\times q\)</span>. Ahora veamos que los productos <span class="math inline">\(A(BC)\)</span> y <span class="math inline">\((AB)C\)</span> además de tener el mismo orden, coinciden en cada elemento. <span class="math inline">\(\begin{array}{rl}  [A(BC)]_{ij} &amp; =\sum_{r=1}^{n} [A]_{ir}[BC]_{rj}\\  &amp; =\sum_{r=1}^{n} [A]_{ir} \sum_{s=1}^{p} [B]_{rs} [C]_{sj}\\  &amp; =\sum_{r=1}^{n}\sum_{s=1}^{p} [A]_{ir}[B]_{rs} [C]_{sj}\\  &amp; =\sum_{s=1}^{p}\sum_{r=1}^{n} [A]_{ir}[B]_{rs} [C]_{sj}\\  &amp; =\sum_{s=1}^{p}(\sum_{r=1}^{n} [A]_{ir}[B]_{rs}) [C]_{sj}\\  &amp; =\sum_{s=1}^{p} [AB]_{is} [C]_{sj}\\  &amp; =[(AB)C]_{ij}  \end{array}\)</span></p>
</div>


<div class="remark">
<p> <span class="remark"><em>Nota. </em></span>  El producto de una matriz cuadrada <span class="math inline">\(A\)</span> de orden <span class="math inline">\(n\times n\)</span>, consigo misma, se puede denotar por <span class="math inline">\(A^{2}=AA\)</span>. Note que <span class="math inline">\(A^{2}\)</span> es de orden <span class="math inline">\(n\times n\)</span>, luego el producto <span class="math inline">\(AA^{2}\)</span> está defindo y se denotará <span class="math inline">\(A^{3}\)</span>. En general, el producto de cualquier matriz cuadrada consigo misma, <span class="math inline">\(r\)</span> veces, está definida y se denota <span class="math inline">\(A^{r}=AA\cdots A\)</span>.</p>
</div>

<p>Ahora veremos las operaciones elementales por filas que corresponden a hacer combinaciones lineales entre las filas de la matriz de coeficientes (equivalente a hacerlo con las ecuaciones del sistema). Las <em>\textit{</em>operaciones elementales por filas* son tres:</p>
<pre><code>(1) Multiplicar una fila de la matriz $A$ por un escalar no nulo $\lambda$.

(2) Intercambio de dos filas de la matriz $A$.

(3) Sustituír la $i$-\&#39;esima fila de la matriz $A$, por la suma de la fila $r$ mas un múltiplo de la fila $s$-ésima.</code></pre>
<p>Podemos denotar en forma de función (entre fila) las operaciones elementales por fila del siguiente modo. Si <span class="math inline">\(A\)</span> es una matriz <span class="math inline">\(m\times n\)</span>, una operación elemental de filas es una función <span class="math inline">\(e\)</span> que se le aplica a la matriz <span class="math inline">\(A\)</span>, asociándole la matriz <span class="math inline">\(e(A)\)</span>, que corresponde al resultado de alguna de las operaciones antes descritas. esto es:</p>
<pre><code>(1) Denotaremos $\lambda e_{r}$ a la operación 
$[e(A)]_{ij}=\left\{ \begin{array}{cc}
\lambda [A]_{ij} &amp; \mbox{ si } i=r \\
\left[A\right]_{ij} &amp; \mbox{ si } i\neq r
\end{array}\right.$, con $r\leq m$ y $\lambda\neq 0$.

(2) Denotaremos $e_{rs}$ a la operación 
$[e(A)]_{ij}=\left\{ \begin{array}{cc}
[A]_{sj} &amp; \mbox{ si } i=r \\
\left[ A\right]_{rj} &amp; \mbox{ si } i=s \\
\left[A\right]_{ij} &amp; \mbox{ en otro caso } 
\end{array}\right.$, con $r\neq s \leq m$.

(3) Denotaremos $\lambda e_{rs}$ a la operación 
$[e(A)]_{ij}=\left\{ \begin{array}{cc}
[A]_{ij}+\lambda [A]_{sj} &amp; \mbox{ si } i=r \\
\left[A\right]_{ij} &amp; \mbox{ si } i\neq r
\end{array}\right.$, con $r\neq s \leq m$.</code></pre>
<p>Note que cualquiera de las tres operaciones elementales por filas se puede “revertir” con una operación del mismo tipo. Para el primer tipo, basta con multiplicar la misma fila por el inverso de <span class="math inline">\(\lambda\)</span>, <span class="math inline">\(\frac{1}{\lambda}\)</span>. Para el intercambio de las filas <span class="math inline">\(r\)</span> y <span class="math inline">\(s\)</span> basta volver a intercambiar las filas. Para el tercer tipo de operación, <span class="math inline">\(\lambda A_{rs}\)</span>, debemos aplicar <span class="math inline">\(-\lambda A_{rs}\)</span> y regresaremos a la matriz original. Esto es la demostración del siguiente teorema.</p>

<div class="theorem">
<p><span id="thm:unnamed-chunk-16" class="theorem"><strong>Teorema 1.3  </strong></span> Para cada operación elemental de filas <span class="math inline">\(e\)</span> existe una operación elemental de filas <span class="math inline">\(e_{1}\)</span> del mismo tipo tal que <span class="math inline">\(e_{1}(e(A))=e(e_{1}(A))=A\)</span>. Es decir, cada operación elemental de filas, tiene una operación inversa del mismo tipo.</p>
</div>


<div class="definition">
<p><span id="def:unnamed-chunk-17" class="definition"><strong>Definición 1.6  </strong></span> Si <span class="math inline">\(A\)</span> y <span class="math inline">\(B\)</span> son dos matrices del mismo orden sobre el mismo cuerpo de escalares y <span class="math inline">\(B\)</span> se obtiene de aplicar una cantidad finita de operaciones elementales por filas a la matriz <span class="math inline">\(A\)</span>, entonces decimos que <em><span class="math inline">\(B\)</span> es equivalente por filas a <span class="math inline">\(A\)</span></em>.</p>
</div>


<div class="remark">
<p> <span class="remark"><em>Nota. </em></span>  Del teorema anterior se puede verificar que si una matriz <span class="math inline">\(B\)</span> es equivalente por filas a otra matriz <span class="math inline">\(A\)</span>, entonces <span class="math inline">\(A\)</span> es equivalente por filas con <span class="math inline">\(B\)</span>. También se puede ver que toda matriz es equivalente por filas a si misma. Por último se puede demostrar que si <span class="math inline">\(A\)</span> es equivalente por filas a <span class="math inline">\(B\)</span> y <span class="math inline">\(B\)</span> es equivalente por filas a <span class="math inline">\(C\)</span>, entonces <span class="math inline">\(A\)</span> es equivalente por filas a <span class="math inline">\(C\)</span>. De lo anterior, se tiene que la equivalencia por filas es una relación de equivalencia.</p>
</div>
<p> Como ya lo hemos mencionado, aplicar una operación elemental por filas es equivalente a hacer combinaciones lineales con las ecuaciones del sistema, por lo tanto al obtener matrices equivalentes por filas tendremos sistemas de ecuaciones equivalentes.</p>

<div class="theorem">
<p><span id="thm:unnamed-chunk-19" class="theorem"><strong>Teorema 1.4  </strong></span> Si <span class="math inline">\(A\)</span> y <span class="math inline">\(B\)</span> son matrices equivalentes por filas, los sistemas homogeneos de ecuaciones lineales <span class="math inline">\(AX=0\)</span> y <span class="math inline">\(BX=0\)</span> tinen exactamente las mismas soluciones.</p>
</div>
 
<div class="proof">
<p> <span class="proof"><em>Demostración. </em></span>  Basta suponer que <span class="math inline">\(B\)</span> se obtiene de aplicar una operación elemental <span class="math inline">\(e\)</span> a la matriz <span class="math inline">\(A\)</span>. Luego, las ecuaciones del sistema <span class="math inline">\(BX=0\)</span> son combinaciones lineales de las ecuaciones del sistema <span class="math inline">\(AX=0\)</span>, por lo que cada solución de <span class="math inline">\(AX=0\)</span> es solución de <span class="math inline">\(BX=0\)</span>. Análogamente, cada solución de <span class="math inline">\(BX=0\)</span> es solución de <span class="math inline">\(AX=0\)</span>, ya que <span class="math inline">\(A\)</span> se obtiene al aplicar la operación elemental inversa de <span class="math inline">\(e\)</span> a la matriz <span class="math inline">\(B\)</span>.</p>
</div>
 
<div class="example">
<p><span id="exm:unnamed-chunk-21" class="example"><strong>Ejemplo 1.5  </strong></span> Dada la matriz de coeficientes <span class="math inline">\(A=\left[ \begin{array}{cccc}  2 &amp; -1 &amp; 3 &amp; 2 \\  1 &amp; 4 &amp; 0 &amp; -1 \\  2 &amp; 6 &amp; -1 &amp; 5  \end{array}\right]\)</span> podemos hallar una matriz escalonada reducida por fila equivalente a <span class="math inline">\(A\)</span>, de la siguiente forma:</p>
<pre><code>$\left[  \begin{array}{cccc}
2 &amp; -1 &amp; 3 &amp; 2 \\
1 &amp; 4 &amp; 0 &amp; -1 \\
2 &amp; 6 &amp; -1 &amp; 5
\end{array}\right]   \stackrel{-2 e_{21}}{\longrightarrow}
\left[  \begin{array}{cccc}
0 &amp; -9 &amp; 3 &amp; 4 \\
1 &amp; 4 &amp; 0 &amp; -1 \\
2 &amp; 6 &amp; -1 &amp; 5
\end{array}\right]  \stackrel{-2 e_{23}}{\longrightarrow}
\left[ 
\begin{array}{cccc}
0 &amp; -9 &amp; 3 &amp; 4 \\
1 &amp; 4 &amp; 0 &amp; -1 \\
0 &amp; -2 &amp; -1 &amp; 7
\end{array}\right] \stackrel{\frac{-1}{2} e_{3}}{\longrightarrow}
\left[ 
\begin{array}{cccc}
    0 &amp; -9 &amp; 3 &amp; 4 \\
    1 &amp; 4 &amp; 0 &amp; -1 \\
    0 &amp; 1 &amp; \frac{1}{2} &amp; \frac{-7}{2}
\end{array}\right] \stackrel{-4 e_{32}}{\longrightarrow}
\left[ 
\begin{array}{cccc}
    0 &amp; -9 &amp; 3 &amp; 4 \\
    1 &amp; 0 &amp; -2 &amp; 13 \\
    0 &amp; 1 &amp; \frac{1}{2} &amp; \frac{-7}{2}
\end{array}\right] \stackrel{9 e_{31}}{\longrightarrow}
\left[ 
\begin{array}{cccc}
    0 &amp; 0 &amp; \frac{15}{2} &amp; \frac{-55}{2} \\
    1 &amp; 0 &amp; -2 &amp; 13 \\
    0 &amp; 1 &amp; \frac{1}{2} &amp; \frac{-7}{2}
\end{array}\right] \stackrel{\frac{2}{15} e_{1}}{\longrightarrow}</code></pre>
<p>    $</p>
<p>De donde se tiene que los sistemas de ecuaciones lineales</p>
$
<span class="math display">\[\begin{array}{ccccc}
2x_{1} &amp; -x_{2} &amp; +3x_{3} &amp; +2x_{4} &amp; =0\\
x_{1} &amp; +4x_{2} &amp;  &amp; -x_{4} &amp;=0\\
2x_{1} &amp; +6x_{2} &amp; -x_{3} &amp; +5x_{4} &amp; =0
\end{array}\]</span>
<p>. $ y</p>
$ 
<span class="math display">\[\begin{array}{ccccc}
    x_{1} &amp;  &amp;  &amp; +\frac{17}{3}x_{4} &amp;=0 \\
 &amp; x_{2} &amp;  &amp; +\frac{-5}{3}x_{4} &amp;=0 \\
  &amp;  &amp; x_{3} &amp; +\frac{-11}{3}x_{4} &amp;=0 
\end{array}\]</span>
<p>. $ son equivalentes y por lo tanto tienen las mismas soluciones. Del segundo sistema salta a la vista que una solución es de la forma <span class="math inline">\((\frac{-17}{3}\lambda,\frac{5}{3}\lambda,\frac{11}{3}\lambda,\lambda)\)</span> para cualquier número real <span class="math inline">\(\lambda\)</span>.</p>
</div>


<div class="example">
<span id="exm:unnamed-chunk-22" class="example"><strong>Ejemplo 1.6  </strong></span> Dada la ecuación con coeficientes en el cuerpo de los números complejos <span class="math inline">\(\mathbb{C}\)</span>: $ 
<span class="math display">\[\begin{array}{ccc}
    -x_{1} &amp; +ix_{2} &amp;=0\\
    -ix_{1} &amp; +3x_{2} &amp;=0\\
    x_{1} &amp; +2x_{2} &amp; =0
    \end{array}\]</span>
<p>. $</p>
<pre><code>La matriz de coeficientes es $A=\left[  \begin{array}{cc}
-1 &amp; i \\
-i &amp; 3 \\
1 &amp; 2 
\end{array}\right]$$ 
Hallemos una matriz escalonada reducida por fila equivalente a $A$:
$$\left[  \begin{array}{cc}
-1 &amp; i \\
-i &amp; 3 \\
1 &amp; 2 
\end{array}\right]   \stackrel{e_{13}}{\longrightarrow}
\left[  \begin{array}{cc}
1 &amp; 2 \\
-i &amp; 3 \\
-1 &amp; i 
\end{array}\right]  \stackrel{i e_{12}}{\longrightarrow}
\left[ 
\begin{array}{cc}
1 &amp; 2 \\
0 &amp; 3+2i \\
-1 &amp; i 
\end{array}\right] \stackrel{1 e_{13}}{\longrightarrow}
\left[ 
\begin{array}{cc}
1 &amp; 2 \\
0 &amp; 3+2i \\
0 &amp; 2+i 
\end{array}\right] \stackrel{\frac{1}{3+2i} e_{2}}{\longrightarrow}$

$\left[ 
\begin{array}{cc}
1 &amp; 2 \\
0 &amp; 1 \\
0 &amp; 2+i 
\end{array}\right] \stackrel{-2 e_{21}}{\longrightarrow}
\left[ 
\begin{array}{cc}
1 &amp; 0 \\
0 &amp; 1 \\
0 &amp; 2+i 
\end{array}\right] \stackrel{-2-i e_{23}}{\longrightarrow}
\left[ 
\begin{array}{cc}
1 &amp; 0 \\
0 &amp; 1 \\
0 &amp; 2+i 
\end{array}\right]$</code></pre>
<p>De donde se tiene que la solución del sistema <span class="math inline">\(AX=0\)</span> es la trivial <span class="math inline">\((0,0,0)\)</span>, ya que <span class="math inline">\(AX=0\)</span> es equivalente al sistema <span class="math inline">\(\left[ \begin{array}{cc} 1 &amp; 0 \\ 0 &amp; 1 \\ 0 &amp; 2+i \end{array}\right] \cdot \left[ \begin{array}{c} x_{1} \\ x_{2} \end{array}\right] = \left[ \begin{array}{c} 0 \\ 0 \end{array}\right]\)</span></p>
</div>

<p>Dada cualquier matriz <span class="math inline">\(A\)</span> de orden <span class="math inline">\(m\times n\)</span>, podemos hallar una matriz equivalente por filas que sea escalonda reducida por filas, realizando un número finito de operaciones por filas según el siguiente algoritmo. Toda fila nula de la matriz se mueven hacia abajo de la matriz por medio de la operación intercambio de filas, de forma que todas ellas queden en las últimas filas de la matriz, es decir, supongamos que existen <span class="math inline">\(r\leq m\)</span> filas no nulas, entonces las últimas filas <span class="math inline">\(r+1, r+2, \cdots, m\)</span> serán las filas de ceros, de forma que el bloque superior <span class="math inline">\(1,2,\cdots, r\)</span> serán las filas no nulas. Luego, considerando esta nueva matriz (la llamaremos <span class="math inline">\(A\)</span>, por comodidad). Sea <span class="math inline">\(a_{1k_{1}}\)</span> el primer elemento no nulo de la primera fila (<span class="math inline">\(k_{1}\)</span> es la columna donde aparece el primer elemento no nulo de la fila <span class="math inline">\(1\)</span>), si <span class="math inline">\(a_{1k_{1}}=1\)</span>, se cumple la condición (1), si no es así, aplicamos la operación <span class="math inline">\(\frac{1}{a_{1k_{1}}} e_{1}\)</span> para hacer que el pivote sea <span class="math inline">\(1\)</span>. Ahora, debemos hacer que todo elemento en esa columna sea cero si está en otra fila (condición (2)), para esto aplicamos la operación <span class="math inline">\(-a_{ik_{1}}e_{i}\)</span> para cada fila <span class="math inline">\(1\neq i\leq r\)</span>. Pasamos a la siguiente fila, <span class="math inline">\(A_{2\ast}\)</span>, consideramos el primer elemento no nulo de dicha fila, <span class="math inline">\(a_{2k_{2}}\)</span>, donde <span class="math inline">\(k_{2}\)</span> es la columna que ocupa. Si <span class="math inline">\(a_{2k_{2}}=1\)</span>, no haremos nada, en otro caso, aplicamos la operación <span class="math inline">\(\frac{1}{a_{2k_{2}}} e_{2}\)</span>, con esto se cumple la condición (1) para esta fila. Ahora aplicamos <span class="math inline">\(-a_{ik_{2}}e_{i}\)</span> para cada fila <span class="math inline">\(2\neq i\leq r\)</span>, con esto se cumple la condición (2). Repetimos este proceso para cada una de las filas no nulas de <span class="math inline">\(A\)</span>, es decir, para las filas <span class="math inline">\(1,2,\cdots, r\)</span>. Ahora ordenamos las filas no nulas intercambiando filas para lograr que se cumpla la condición (4), es decir, que se cumpla que <span class="math inline">\(p_{1}&lt; p_{2}&lt; \cdots &lt; p_{r}\)</span>, llamando <span class="math inline">\(p_{i}\)</span> a la columna del pivote de la fila <span class="math inline">\(i\)</span> luego de aplicar las operaciones elementales por filas. Es claro que estas operaciones son siempre posibles de aplicar a cualquier matriz, en un número finito de pasos. De lo anterior podemos concluir que siempre podemos reducir una matriz a una escalonada. Podemos expresarlo como un teorema, cuya demostración es el algoritmo anterior.</p>

<div class="theorem">
<p><span id="thm:unnamed-chunk-23" class="theorem"><strong>Teorema 1.5  </strong></span> Toda matriz <span class="math inline">\(m\times n\)</span> sobre el cuerpo <span class="math inline">\(\mathbb{F}\)</span> es equivalente por filas a una matriz escalonada reducida por filas.</p>
</div>


<div class="theorem">
<p><span id="thm:unnamed-chunk-24" class="theorem"><strong>Teorema 1.6  </strong></span> Si <span class="math inline">\(A\)</span> es una matriz <span class="math inline">\(m\times n\)</span> con <span class="math inline">\(m&lt;n\)</span>, el sistema homogéneo de ecuaciones lineales <span class="math inline">\(AX=0\)</span> tiene una solución no trivial.</p>
</div>
 
<div class="proof">
<p> <span class="proof"><em>Demostración. </em></span>  Sea <span class="math inline">\(R\)</span> una matriz escalón reducida por filas equivalente por filas a la matriz <span class="math inline">\(A\)</span>. Entonces <span class="math inline">\(AX=0\)</span> y <span class="math inline">\(RX=0\)</span> tienen exactamente las mismas soluciones. Supongamos que <span class="math inline">\(R\)</span> tiene <span class="math inline">\(r\)</span> filas no nulas, luego <span class="math inline">\(r&lt;n\)</span>, luego el sistema de ecuaciones <span class="math inline">\(RX=0\)</span> consta de <span class="math inline">\(r\)</span> ecuaciones no triviales, a saber, suponiendo que <span class="math inline">\(x_{k_{i}}\)</span> es la incógnita que aparece en la posición del pivote de la fila <span class="math inline">\(i\)</span>, <span class="math display">\[\begin{array}{ccc}
    x_{k_{1}}+&amp; \sum_{j=1}^{n-r}c_{1j}u_{j}=&amp;0\\
    \vdots &amp; &amp; \vdots\\
    x_{k_{r}}+&amp; \sum_{j=1}^{n-r}c_{rj}u_{j}=&amp;0
    \end{array}\]</span> donde las <span class="math inline">\(n-r\)</span> incógnitas diferentes de <span class="math inline">\(x_{k_{1}}, x_{k_{2}},\cdots, x_{k_{r}}\)</span> las denotamos <span class="math inline">\(u_{1}, u_{2}, \cdots, u_{n-r}\)</span>. Note que la incógnita <span class="math inline">\(x_{k_{i}}\)</span> aparece solo en la <span class="math inline">\(i\)</span>-ésima ecuación. De esta forma, podemos dar valores arbitrarios a <span class="math inline">\(u_{1}, u_{2}, \cdots, u_{n-r}\)</span> y así hallar una solución no trivial, que a su vez es solución del sistema <span class="math inline">\(AX=0\)</span>.</p>
</div>


<div class="theorem">
<p><span id="thm:teorema6" class="theorem"><strong>Teorema 1.7  </strong></span> Si <span class="math inline">\(A\)</span> es una matriz cuadrada <span class="math inline">\(n\times n\)</span>. Entonces <span class="math inline">\(A\)</span> es equivalente por filas a la matriz identidad si y solo si, el sistema de ecuaciones <span class="math inline">\(AX=0\)</span> tiene solo la solución trivial <span class="math inline">\(X=0\)</span>.</p>
</div>


<div class="proof">
<p> <span class="proof"><em>Demostración. </em></span>  Si <span class="math inline">\(A\)</span> es equivalente por filas a la identidad, por el teorema anterior <span class="math inline">\(AX=0\)</span> y <span class="math inline">\(IX=0\)</span> tienen exactamente las mismas soluciones, por lo tanto la única solución es <span class="math inline">\(X=0\)</span>. Ahora, supongamos que <span class="math inline">\(AX=0\)</span> tiene unicamente la solución trivial; supongamos que <span class="math inline">\(R\)</span> es la matriz escalonada reducida equivalente a <span class="math inline">\(A\)</span>, y sea <span class="math inline">\(r\leq n\)</span> el número de filas no nulas; entonces <span class="math inline">\(RX=0\)</span> tiene unicamente la solución trivial (por el teorema anterior), luego <span class="math inline">\(r\geq n\)</span>, por lo tanto <span class="math inline">\(r=n\)</span>, por lo tanto <span class="math inline">\(R=I\)</span>.</p>
</div>

<p>Todos los teoremas anteriores hacen referencia a sistemas homogéneos <span class="math inline">\(AX=0\)</span>, el cual siempre tiene solución, la solución trivial <span class="math inline">\(X=0\)</span>. Cabe preguntar que sucede con los sistemas no homogéneos <span class="math inline">\(AX=B\)</span>. Un sistema no homogéneo no tiene necesariamente solución. Estudiemos esto a continuación. Dado el sistema no homogéneo <span class="math inline">\(AX=B\)</span>, con <span class="math inline">\(A\)</span> de orden <span class="math inline">\(m\times n\)</span>; consideramos la <em>matriz aumentada</em>, <span class="math inline">\(\hat{A}\)</span> de orden <span class="math inline">\(m\times (n+1)\)</span>, cuyas primeras <span class="math inline">\(n\)</span> columnas son iguales a las columnas de <span class="math inline">\(A\)</span> y la columna <span class="math inline">\(n+1\)</span> corresponde a <span class="math inline">\(B\)</span>, es decir, <span class="math inline">\(\hat{A}_{\ast j}=A_{\ast j}\)</span> para <span class="math inline">\(j\leq n\)</span> y <span class="math inline">\(\hat{A}_{\ast n+1}=B_{1}\)</span>. Se aplicará a esta matriz, <span class="math inline">\(\hat{A}\)</span> las mismas operaciones elementales por filas que se le aplican a la matriz <span class="math inline">\(A\)</span> para llevarla a una matriz escalonada reducidas por filas <span class="math inline">\(R\)</span>, y así se obtendrá una matriz <span class="math inline">\(\hat{R}\)</span> cuya última fila son los escalares <span class="math inline">\(z_{1}, z_{2},\cdots z_{m}\)</span> (que serán combinaciones lineales de los coeficientes <span class="math inline">\(b_{1}, b_{2},\cdots, b_{m}\)</span>). Es claro que los sistemas <span class="math inline">\(AX=B\)</span> y <span class="math inline">\(RX=Z\)</span> tienen las mismas soluciones (la demostración es análoga al de los sistemas homogéneos). Es fácil ver cuando el sistema <span class="math inline">\(\hat{R}X=Z\)</span> tiene solución. Si <span class="math inline">\(\hat{R}\)</span> tiene <span class="math inline">\(r\)</span> filas no nulas, donde el pivote de la fila <span class="math inline">\(i\)</span> está en la columna <span class="math inline">\(k_{i}\)</span> entonces las primeras <span class="math inline">\(r\)</span> ecuaciones expresarán las primeras <span class="math inline">\(r\)</span> incógnitas, <span class="math inline">\(x_{k_{1}}, x_{k_{2}}, \cdots, x_{k_{r}}\)</span> por las <span class="math inline">\(n-r\)</span> incógnitas restantes, <span class="math inline">\(x_{j}\)</span> y los escalares <span class="math inline">\(z_{1}, z_{2},\cdots, z_{r}\)</span>. Y las últimas <span class="math inline">\(m-r\)</span> ecuaciones son: <span class="math display">\[\begin{array}{cc}
0= &amp; z_{r+1}\\
\vdots &amp; \vdots\\
0= &amp; z_{m}
\end{array}\]</span> Por lo tanto, para que el sistema tenga solución debe suceder que <span class="math inline">\(z_{r+1}=z_{r+2}=\cdots=z_{m}=0\)</span>. Si esto ocurre entonces las soluciones del sistema se obtienen dando valores arbitrarios a la <span class="math inline">\(n-j\)</span> incógnitas <span class="math inline">\(x_{j}\)</span>.</p>

<div class="example">
<p><span id="exm:unnamed-chunk-27" class="example"><strong>Ejemplo 1.7  </strong></span> Sea <span class="math display">\[A=\left[\begin{array}{ccc}
    1 &amp; -2 &amp; 1\\
    2 &amp; 1 &amp; 1\\
    0 &amp; 5 &amp; -1
    \end{array} \right] \]</span> la matriz de coeficientes del sistema <span class="math inline">\(AX=B\)</span>, donde <span class="math inline">\(B=\left[\begin{array}{c}  b_{1}\\  b_{2}\\  b_{3}  \end{array} \right]\)</span>. Luego la matriz extendida es <span class="math inline">\(\hat{A}=\left[\begin{array}{ccc|c}  1 &amp; -2 &amp; 1 &amp; b_{1}\\  2 &amp; 1 &amp; 1 &amp; b_{2}\\  0 &amp; 5 &amp; -1 &amp; b_{3}  \end{array} \right]\)</span></p>
<pre><code>Reducimos la matriz:

$\left[\begin{array}{ccc|c}
1 &amp; -2 &amp; 1 &amp; b_{1}\\
2 &amp; 1 &amp; 1 &amp; b_{2}\\
0 &amp; 5 &amp; -1 &amp; b_{3}
\end{array} \right] \stackrel{-2 e_{12}}{\longrightarrow} 
\left[\begin{array}{ccc|c}
1 &amp; -2 &amp; 1 &amp; b_{1}\\
0 &amp; 5 &amp; -1 &amp; b_{2}-2b_{1}\\
0 &amp; 5 &amp; -1 &amp; b_{3}
\end{array} \right] \stackrel{\frac{1}{5} e_{2}}{\longrightarrow}
\left[\begin{array}{ccc|c}
1 &amp; -2 &amp; 1 &amp; b_{1}\\
0 &amp; 1 &amp; -\frac{1}{5} &amp; \frac{1}{5}(b_{2}-2b_{1})\\
0 &amp; 5 &amp; -1 &amp; b_{3}
\end{array} \right] \stackrel{ 2e_{21}}{\longrightarrow}</code></pre>
<p> $ Luego, el sistema tiene solución solo si <span class="math inline">\(2b_{1}-b_{2}+b_{3}=0\)</span>. Si esta condición se cumple, entonces una solución para el sistema es de la forma: <span class="math inline">\(\begin{array}{cc}  x_{1}= &amp;-\frac{3}{5}x_{3}+\frac{1}{5}(b_{1}+2b_{2})\\  x_{2}= &amp;\frac{1}{5}x_{3}+\frac{1}{5}(b_{2}-2b_{1})  \end{array}\)</span> para cualquier valor de <span class="math inline">\(x_{3}\)</span>.</p>
</div>

<p>Note que la igualdad <span class="math inline">\(A(BC)=(AB)C\)</span> implica, entre otras cosas, que combinaciones lineales de combinaciones lineales de las filas de <span class="math inline">\(C\)</span>, son otra vez combinaciones lineales de las filas de <span class="math inline">\(C\)</span>. Si <span class="math inline">\(C\)</span> es una matriz que se obtiene de aplicar una operación elemental de fila a <span class="math inline">\(B\)</span>, entonces las filas de <span class="math inline">\(C\)</span> son combinación lineal de las filas de <span class="math inline">\(B\)</span>, por lo tanto debe existir una matriz <span class="math inline">\(A\)</span>, tal que <span class="math inline">\(C=AB\)</span>. Pueden existir muchas matrices con tal propiedad; veremos como escoger una de ellas.</p>

<div class="definition">
<p><span id="def:unnamed-chunk-28" class="definition"><strong>Definición 1.7  </strong></span> Una matriz <span class="math inline">\(m\times m\)</span> es una <em>matriz elemental</em> si se obtiene de aplicar una sola operación elemental de filas a la matriz identidad (de orden <span class="math inline">\(m\times m\)</span>).</p>
</div>


<div class="example">
<p><span id="exm:unnamed-chunk-29" class="example"><strong>Ejemplo 1.8  </strong></span> Una matriz elementa de orden <span class="math inline">\(2\times 2\)</span> es necesariamente como alguna de las siguientes: <span class="math display">\[ \left[ \begin{array}{cc}
    0 &amp; 1\\
    1 &amp; 0
    \end{array} \right] , 
    \left[ \begin{array}{cc}
    1 &amp; \lambda\\
    0 &amp; 1
    \end{array} \right] ,
    \left[ \begin{array}{cc}
    1 &amp; 0\\
    \lambda &amp; 1
    \end{array} \right]  \mbox{ con }\lambda\in \mathbb{F}\]</span> o</p>
<pre><code>$$\left[ \begin{array}{cc}
\delta &amp; 0\\
0 &amp; 1
\end{array} \right] , 
\left[ \begin{array}{cc}
1 &amp; 0\\
0 &amp; \delta
\end{array} \right] \mbox{ con } \delta\neq 0$$</code></pre>
</div>


<div class="theorem">
<p><span id="thm:unnamed-chunk-30" class="theorem"><strong>Teorema 1.8  </strong></span> Sea <span class="math inline">\(E\)</span> una matriz elemental que corresponde a la operación elemental por filas <span class="math inline">\(e\)</span>. Sea <span class="math inline">\(A\)</span> una matriz <span class="math inline">\(m\times n\)</span>. Entonces <span class="math inline">\(e(A)=EA\)</span>.</p>
</div>


<div class="proof">
<p> <span class="proof"><em>Demostración. </em></span>  Note que el elemento <span class="math inline">\([EA]_{ij}\)</span> se obtien de la <span class="math inline">\(i\)</span>-ésima fila de <span class="math inline">\(E\)</span> y la <span class="math inline">\(j\)</span>-ésima columna de <span class="math inline">\(A\)</span>. Estudiemos cada tipo de operación por separado, comenzaremos con la mas complicada y las otras dos se dejan como ejercicio. Supongamos que <span class="math inline">\(e= \lambda e_{sr}\)</span> (se sustituye la fila <span class="math inline">\(r\)</span> por la fila <span class="math inline">\(r\)</span> mas <span class="math inline">\(\lambda\)</span> veces la fila <span class="math inline">\(s\)</span>). Se tiene que <span class="math inline">\(E=\lambda e_{sr}(I)\)</span>, por lo tanto: <span class="math display">\[[E]_{ik}=
        \left\{ \begin{array}{lc}
        \delta_{ik} &amp; i\neq r\\
        \delta_{rk}+\lambda \delta_{sk} &amp; i=r
        \end{array} 
        \right.\]</span> Luego <span class="math display">\[ [EA]_{ij}=\sum_{k=1}^{m} [E]_{ik}[A]_{kj}=
    \left\{ \begin{array}{lc}
        a_{ik} &amp; i\neq r \\
        a_{rk}+\lambda a_{sk} &amp; i=r
        \end{array} 
    \right. 
\]</span> Por lo tanto <span class="math inline">\(EA=e(A)\)</span>.</p>
</div>


<div class="corollary">
<p><span id="cor:unnamed-chunk-32" class="corollary"><strong>Corolario 1.1  </strong></span> Sean <span class="math inline">\(A\)</span> y <span class="math inline">\(B\)</span> matrices de orden <span class="math inline">\(m\times n\)</span> sobre el cuerpo <span class="math inline">\(\mathbb{F}\)</span>. Entonces <span class="math inline">\(B\)</span> es equivalente por filas a <span class="math inline">\(A\)</span> si y solo si <span class="math inline">\(B=PA\)</span>, donde <span class="math inline">\(P\)</span> es un producto de matrices elementales <span class="math inline">\(m\times m\)</span>.</p>
</div>


<div class="proof">
<p> <span class="proof"><em>Demostración. </em></span>  Supongamos que <span class="math inline">\(E_{1}, E_{2},\cdots, E_{k}\)</span> matrices elementales correspondientes a las operaciones elementales por fila <span class="math inline">\(e_{1}, e_{2},\cdots, e_{k}\)</span>. Entonces <span class="math inline">\(B=e_{1}\circ e_{2}\circ\cdots \circ e_{k}(A)\)</span> si y solo si <span class="math inline">\(B=E_{1} E_{2} \cdots E_{k} A=PA\)</span>, con <span class="math inline">\(P=E_{1} E_{2} \cdots E_{k}\)</span>.</p>
</div>
<p> Si <span class="math inline">\(A\)</span> es una matriz equivalente por filas a <span class="math inline">\(B\)</span>, el corolario anterior asegura que existe <span class="math inline">\(P\)</span>, tal que <span class="math inline">\(B=PA\)</span>, donde <span class="math inline">\(P\)</span> es producto de matrices elementales. Por otro lado se tiene que <span class="math inline">\(B\)</span> es equivalente por filas a <span class="math inline">\(A\)</span>, luego existe una matriz <span class="math inline">\(Q\)</span>, producto de matrices elementales, tal que <span class="math inline">\(A=QB\)</span>. En particular, esto es cierto para la matriz identidad, es decir <span class="math inline">\(I=QB=QP\)</span>. Veremos que la existencia de la matriz <span class="math inline">\(Q\)</span>, tal que <span class="math inline">\(QP=I\)</span> es equivalente al hecho de que <span class="math inline">\(P\)</span> es producto de matrices elementales.</p>

<div class="definition">
<p><span id="def:unnamed-chunk-34" class="definition"><strong>Definición 1.8  </strong></span> Sea <span class="math inline">\(A\)</span> una matriz (cuadrada) <span class="math inline">\(n\times n\)</span> sobre el cuerpo <span class="math inline">\(\mathbb{F}\)</span>. Una matriz <span class="math inline">\(B\)</span> <span class="math inline">\(n\times n\)</span>, tal que <span class="math inline">\(BA=I\)</span> se llama <em>inversa izquierda</em> de <span class="math inline">\(A\)</span>; una matriz <span class="math inline">\(B\)</span> <span class="math inline">\(n\times n\)</span>, tal que <span class="math inline">\(AB=I\)</span> se llama <em>inversa derecha</em> de <span class="math inline">\(A\)</span>. Si <span class="math inline">\(AB=BA=I\)</span>, entonces <span class="math inline">\(B\)</span> se llama <em>inversa bilateral</em> de <span class="math inline">\(A\)</span> y en este caso se dice que <span class="math inline">\(A\)</span> es <em>invertible</em>.</p>
</div>


<div class="lemma">
<p><span id="lem:unnamed-chunk-35" class="lemma"><strong>Lema 1.1  </strong></span> Si una matriz <span class="math inline">\(A\)</span> tiene una inversa izquierda <span class="math inline">\(B\)</span> y una inversa derecha <span class="math inline">\(C\)</span>, entonces <span class="math inline">\(B=C\)</span>.</p>
</div>


<div class="proof">
<p> <span class="proof"><em>Demostración. </em></span>  Suponga que <span class="math inline">\(BA=I\)</span> y <span class="math inline">\(AC=I\)</span>. Entonces <span class="math inline">\(B=BI=B(AC)=(BA)C=IC=C\)</span></p>
</div>

<p>Del corolario anterior tenemos que si <span class="math inline">\(A\)</span> tiene una inversa derecha y una inversa izquierda, entonces son iguales, la llamos <em>la inversa de <span class="math inline">\(A\)</span></em> y la denotámos <span class="math inline">\(A^{-1}\)</span>.</p>

<div class="theorem">
<p><span id="thm:unnamed-chunk-37" class="theorem"><strong>Teorema 1.9  </strong></span> Dadas las matrices <span class="math inline">\(A\)</span> y <span class="math inline">\(B\)</span> de orden <span class="math inline">\(n\times n\)</span> sobre el cuerpo <span class="math inline">\(\mathbb{F}\)</span>. Se tiene que:</p>
<pre><code>    (1) Si $A$ es invertible, entonces $A^{-1}$ también lo es y $(A^{-1})^{-1}=A$.
    (2) Si $A$ y $B$ son invertibles, entonces $AB$ también lo es y $(AB)^{-1}=B^{-1}A^{-1}$.
&lt;/div&gt;\EndKnitrBlock{theorem}</code></pre>

<div class="proof">
<p> <span class="proof"><em>Demostración. </em></span>  De la simetría de la definición de inversa, se sigue la parte <span class="math inline">\(1\)</span>. Para la segunda parte se sigue de <span class="math inline">\((AB)(B^{-1}A^{-1})=A(BB^{-1})A^{-1}=AIA^{-1}=AA^{-1}=I\)</span> y <span class="math inline">\((B^{-1}A^{-1})(AB)=B^{-1}(A^{-1}A)B=B^{-1}IB=B^{-1}B=I\)</span>.</p>
</div>

<p>Del resultado anterior se tiene que el producto de matrices invertible, es invertible.</p>

<div class="theorem">
<p><span id="thm:unnamed-chunk-39" class="theorem"><strong>Teorema 1.10  </strong></span> Toda matriz elemental es invertible.</p>
</div>
 
<div class="proof">
<p> <span class="proof"><em>Demostración. </em></span>  Sea <span class="math inline">\(E\)</span> una matriz elemental y sea <span class="math inline">\(e\)</span> la operación elemental de filas que corresponde a <span class="math inline">\(E\)</span>, es decir, <span class="math inline">\(E=e(I)\)</span>. Sea <span class="math inline">\(\hat{e}\)</span> la operación inversa de <span class="math inline">\(e\)</span>, y <span class="math inline">\(\hat{E}=\hat{e}(I)\)</span>. Entonces <span class="math inline">\(\hat{E}E=\hat{e}(E)=\hat{e}(e(I))=(\hat{e}\circ e) (I)= I\)</span>. Análogamente se tiene que <span class="math inline">\(E\hat{E}=I\)</span>. Luego <span class="math inline">\(\hat{E}=E^{-1}\)</span>.</p>
</div>


<div class="theorem">
<p><span id="thm:unnamed-chunk-41" class="theorem"><strong>Teorema 1.11  </strong></span> Sea <span class="math inline">\(A\)</span> una matriz <span class="math inline">\(n\times n\)</span>. Entonces los siguientes enunciados son equivalentes:</p>
<pre><code>    (1) $A$ es invertible.
    (2) $A$ es equivalente por filas a la identidad (de orden $n\times n$).
    (3) $A$ es producto de matrices elementales.</code></pre>
</div>
 
<div class="proof">
<p> <span class="proof"><em>Demostración. </em></span>  Sea <span class="math inline">\(R=E_{1}E_{2}\cdots E_{n}A\)</span> una matriz esacalonada reducida equivalente por filas a la matriz <span class="math inline">\(A\)</span> (donde <span class="math inline">\(E_{1}E_{2}\cdots E_{n}\)</span> son matrices elementales). Entonces, <span class="math inline">\(A=E_{n}^{-1}\cdots E_{2}^{-1}E_{1}^{-1}R\)</span>, ya que las matrices elementales son invertibles. Como el producto de matrices invertibles, es invertible, <span class="math inline">\(A\)</span> es invertible si y solo si <span class="math inline">\(R\)</span> lo es; como <span class="math inline">\(R\)</span> es una matriz cuadrada esacalonada reducida por filas, entonces <span class="math inline">\(R\)</span> es invertible si y solo si <span class="math inline">\(R\)</span> es la identidad. Luego, <span class="math inline">\(A\)</span> es invertible si y solo si <span class="math inline">\(R=I\)</span>, entonces, <span class="math inline">\(A=E_{n}^{-1}\cdots E_{2}^{-1}E_{1}^{-1}I=E_{n}^{-1}\cdots E_{2}^{-1}E_{1}^{-1}\)</span>.</p>
</div>


<div class="corollary">
<p><span id="cor:unnamed-chunk-43" class="corollary"><strong>Corolario 1.2  </strong></span> Si <span class="math inline">\(A\)</span> es una matriz invertible <span class="math inline">\(n\times n\)</span> y si la sucesión de operaciones elementales <span class="math inline">\(e_{1}\circ e_{2}\circ \cdots \circ e_{n}\)</span> reduce a la matriz <span class="math inline">\(A\)</span> a la identidad, entonces la misma sucesión de operaciones elementales aplicadas a <span class="math inline">\(I\)</span>, nos da <span class="math inline">\(A^{-1}\)</span>, la inversa de <span class="math inline">\(A\)</span>.</p>
</div>


<div class="corollary">
<p><span id="cor:unnamed-chunk-44" class="corollary"><strong>Corolario 1.3  </strong></span> Sean <span class="math inline">\(A\)</span> y <span class="math inline">\(B\)</span> dos matrices <span class="math inline">\(m\times n\)</span>. Entonces <span class="math inline">\(B\)</span> es equivalente por filas a <span class="math inline">\(A\)</span> si y solo si <span class="math inline">\(B=PA\)</span>, donde <span class="math inline">\(P\)</span> es una matriz invertible <span class="math inline">\(m\times m\)</span>.</p>
</div>
 
<div class="theorem">
<p><span id="thm:unnamed-chunk-45" class="theorem"><strong>Teorema 1.12  </strong></span> Sea <span class="math inline">\(A\)</span> una matriz <span class="math inline">\(n\times n\)</span>. Entonces los siguientes enunciados son equivalentes:</p>
<pre><code>(1) $A$ es invertible.
(2) El sistema homogéneo $AX=0$ tiene una única solución ($X=0$).
(3) El sistema de ecuaciones asociado a $AX=B$ tiene una solución $X$ para cada matriz $B$ de orden $n\times 1$.
&lt;/div&gt;\EndKnitrBlock{theorem}</code></pre>

<div class="proof">
<p> <span class="proof"><em>Demostración. </em></span>  El sistema homogéneo <span class="math inline">\(AX=0\)</span> si y solo si <span class="math inline">\(A\)</span> es equivalente por filas al la identidad ( por el teorema <a href="#thm:teorema6">1.7</a>. Del teorema anterior, se tiene que <span class="math inline">\((1)\)</span> y <span class="math inline">\((2)\)</span> son equivalentes. Ahora supongámos que <span class="math inline">\(A\)</span> es invertible, entonces la solución de <span class="math inline">\(AX=B\)</span> viene dada por <span class="math inline">\(X=A^{-1}\)</span>. Recíprocamente, supongamos que <span class="math inline">\(AX=B\)</span> tiene una solución para cada <span class="math inline">\(B\)</span>. Sea <span class="math inline">\(R\)</span> la matriz escalonada reducida por filas equivalente por filas a <span class="math inline">\(A\)</span>. Necesariamente <span class="math inline">\(R=I\)</span>, ya que si <span class="math inline">\(R\)</span> tiene al menos una fila identicamente igual a cero, entonces el sistema <span class="math inline">\(RX=C\)</span>, donde <span class="math display">\[C=\left[ \begin{array}{c}
    0\\
    0\\
    \vdots\\
    0\\
    1
    \end{array}\right] \]</span> no tiene solución, lo que es una contradicción. Por lo tanto se tiene que <span class="math inline">\(R=I\)</span>.</p>
</div>


<div class="corollary">
<p><span id="cor:unnamed-chunk-47" class="corollary"><strong>Corolario 1.4  </strong></span> Una matriz cuadrada que tiene una inversa izquierda o una inversa a la derecha es invertible.</p>
</div>


<div class="proof">
<p> <span class="proof"><em>Demostración. </em></span>  Sea <span class="math inline">\(A\)</span> una matriz <span class="math inline">\(n\times n\)</span>. Supongamos que <span class="math inline">\(A\)</span> tiene una inversa a la izquierda, es decir, existe <span class="math inline">\(B\)</span> tal que <span class="math inline">\(BA=I\)</span>. Así, <span class="math inline">\(AX=0\)</span> tiene unicamente la solución trivial, ya que <span class="math inline">\(X=IX=B(AX)\)</span>. Por lo tanto <span class="math inline">\(A\)</span> es invertible. Supóngase que <span class="math inline">\(A\)</span> tiene una inversa a la derecha, es decir, existe <span class="math inline">\(C\)</span> tal que <span class="math inline">\(AC=I\)</span>. entoces <span class="math inline">\(C\)</span> tiene una inversa a la izquierda y por lo tanto es invertible, así <span class="math inline">\(A=ACC^{-1}=IC^{-1}=C^{-1}\)</span> de donde se tiene que <span class="math inline">\(A\)</span> es invertible de inversa <span class="math inline">\(C\)</span>.</p>
</div>


<div class="corollary">
<p><span id="cor:unnamed-chunk-49" class="corollary"><strong>Corolario 1.5  </strong></span> Sea <span class="math inline">\(A=A_{1}A_{2}\cdots A_{n}\)</span>, donde <span class="math inline">\(A_{1}, A_{2}, \cdots , A_{n}\)</span> son matrices cuadradas. Entonces <span class="math inline">\(A\)</span> es invertible si y solo si cada <span class="math inline">\(A_{i}\)</span> es invertible.</p>
</div>
 
<div class="proof">
<p> <span class="proof"><em>Demostración. </em></span>  Supongamos que cada <span class="math inline">\(A_{i}\)</span> es invertible, como el producto de matrices invertibles es invertible, se tiene que <span class="math inline">\(A\)</span> es invertible. Recíprocamente, supongamos que <span class="math inline">\(A\)</span> es invertible, entonces <span class="math inline">\(AX=0\)</span> tiene unicamente la solución trivial. Por lo tanto, <span class="math inline">\((A_{1}A_{2}\cdots A_{n-1})A_{n}X=AX=0\)</span> tiene unicamente la solución trivial, si y solo si <span class="math inline">\(A_{n}X=0\)</span> tiene solo la solución trivial, de donde se sigue que <span class="math inline">\(A_{n}\)</span> es invertible. Luego, <span class="math inline">\(AA^{-1}=A_{1}A_{2}\cdots A_{n-1}\)</span>, considerando <span class="math inline">\((A_{1}A_{2}\cdots A_{n-2})A_{n-1}X=AA^{-1}X=0\)</span>, de forma análoga a lo anterior, se puede demostrar que <span class="math inline">\(A_{n-1}\)</span> es invertible. Continuando de esta forma se demuestra que cada <span class="math inline">\(A_{i}\)</span> es invertible.</p>
</div>


<div class="remark">
<p> <span class="remark"><em>Nota. </em></span>  Sea <span class="math inline">\(A\)</span> una matriz <span class="math inline">\(m\times n\)</span> y sea <span class="math inline">\(AX=B\)</span>, y sea <span class="math inline">\(R\)</span> la matriz escalonada reducida por filas equivalentes por fila a <span class="math inline">\(A\)</span>, entonces <span class="math inline">\(R=PA\)</span>, donde <span class="math inline">\(P\)</span> es una matriz invertible <span class="math inline">\(m\times m\)</span>; las soluciones de <span class="math inline">\(RX=PB\)</span> son las mismas que las del sistema <span class="math inline">\(AX=B\)</span>. Hallar <span class="math inline">\(PB\)</span> es equivalente a reducir por filas la matriz <span class="math inline">\(A\)</span>, esto se hace considerando la matriz aumentada <span class="math inline">\(\hat{A}\)</span> y aplicandole operaciones elementales por fila hasta reducir a <span class="math inline">\(A\)</span> a una matriz escalonada reducida, lo obtenido en la última columna será la matriz <span class="math inline">\(PB\)</span>.</p>
</div>


<div class="example">
<p><span id="exm:unnamed-chunk-52" class="example"><strong>Ejemplo 1.9  </strong></span> Sea $A=$ la matriz de coeficientes del sistema <span class="math inline">\(AX=B\)</span>, donde <span class="math inline">\(B=\left[\begin{array}{c}  b_{1}\\  b_{2}  \end{array} \right]\)</span>. Luego la matriz extendida es</p>
<p><span class="math inline">\(\hat{A}=\left[\begin{array}{cc|c}  2 &amp; -1 &amp; b_{1}\\  1 &amp; 3 &amp; b_{2}  \end{array} \right]\)</span></p>
<pre><code>Reducimos la matriz:
$\left[\begin{array}{cc|c}
2 &amp; -1 &amp; b_{1}\\
1 &amp; 3 &amp; b_{2}
\end{array} \right] \stackrel{e_{12}}{\longrightarrow} 
\left[\begin{array}{cc|c}
1 &amp; 3 &amp; b_{2}\\
2 &amp; -1 &amp; b_{1}
\end{array} \right] \stackrel{-2 e_{12}}{\longrightarrow}
\left[\begin{array}{cc|c}
1 &amp; 3 &amp; b_{2}\\
0 &amp; -7 &amp; b_{1}-2b_{2}
\end{array} \right] \stackrel{ -\frac{1}{7}e_{2}}{\longrightarrow}
\left[\begin{array}{cc|c}
1 &amp; 3 &amp;   b_{2}\\
0 &amp; 1 &amp; \frac{1}{7}(2b_{2}-b_{1})
\end{array} \right] \stackrel{ -3e_{21}}{\longrightarrow}
\left[\begin{array}{cc|c}
1 &amp; 0 &amp;  \frac{1}{7}(b_{2}+3b_{1})\\
0 &amp; 1 &amp; \frac{1}{7}(2b_{2}-b_{1})
\end{array} \right]$

De donde se tiene que $PB=\left[ \begin{array}{c}
\frac{1}{7}(b_{2}+3b_{1})\\
\frac{1}{7}(2b_{2}-b_{1})
\end{array}\right] $, o también que $A^{-1}=\left[\begin{array}{cc}
\frac{3}{7} &amp; \frac{1}{7}\\
-\frac{1}{7} &amp; \frac{2}{7} 
\end{array} \right]$.

También podemos llegar a la inversa de $A$ aplicando las operaciones elementales antes descritas para reducir a $A$, a la identidad. Es decir:
$\left[\begin{array}{cc|cc}
2 &amp; -1 &amp; 1 &amp; 0\\
1 &amp; 3 &amp; 0 &amp; 1
\end{array} \right] \stackrel{e_{12}}{\longrightarrow} 
\left[\begin{array}{cc|cc}
1 &amp; 3 &amp; 0 &amp; 1\\
2 &amp; -1 &amp; 1 &amp; 0
\end{array} \right] \stackrel{-2 e_{12}}{\longrightarrow}
\cdots 
\left[\begin{array}{cc|cc}
1 &amp; 0 &amp;  \frac{3}{7} &amp; \frac{1}{7}\\
0 &amp; 1 &amp;  -\frac{1}{7} &amp; \frac{2}{7}
\end{array} \right]$</code></pre>
</div>

</div>
</div>
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-78759535-1', 'auto');
ga('send', 'pageview');  
</script>
            </section>

          </div>
        </div>
      </div>


    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/synergyvision/Algebra/edit/master/bookdown/%s",
"text": "Edit"
},
"download": null,
"toc": {
"collapse": "none"
},
"search": false
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
